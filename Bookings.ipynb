{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bookings.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNKMf1pUJx0f1AbaJBKIAI7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alejandromanas/GoogleColab_public/blob/master/Bookings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moNucPTF2tVw",
        "colab_type": "text"
      },
      "source": [
        "# Hotel Bookings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UM_f4iFGabfl",
        "colab_type": "text"
      },
      "source": [
        "Libraries & Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qk6izRTUaYsy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "\n",
        "#Metrics\n",
        "\n",
        "def predict_metrics(X,y,model):\n",
        "        y_pred = pd.Series(model.predict(X))\n",
        "        y_prob= model.predict_proba(X) \n",
        "        \n",
        "        # Accuracy  \n",
        "        print('Score Acc',str(metrics.accuracy_score(y,y_pred)))\n",
        "        \n",
        "        # AUC\n",
        "        fpr, tpr, threshold = metrics.roc_curve(y, y_prob[:,1])\n",
        "        roc_auc = metrics.auc(fpr, tpr)\n",
        "        print('AUC = %0.2f' % roc_auc)\n",
        "        \n",
        "        # Logloss\n",
        "        Logloss = metrics.log_loss(y, y_prob[:,1])\n",
        "        print('LogLoss = %0.2f' % Logloss)\n",
        "        \n",
        "        return y_pred,y_prob\n",
        "\n",
        "# Time execution mesure\n",
        "def tic():\n",
        "    global _start_time \n",
        "    _start_time = time.time()\n",
        "\n",
        "def tac():\n",
        "    t_sec = round(time.time() - _start_time)\n",
        "    (t_min, t_sec) = divmod(t_sec,60)\n",
        "    (t_hour,t_min) = divmod(t_min,60) \n",
        "    time_elapsed=print('Time passed: {}hour:{}min:{}sec'.format(t_hour,t_min,t_sec))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdoP7tFH32k-",
        "colab_type": "text"
      },
      "source": [
        "### Loading Files from Github"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8PMj8JAE7Gu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import data from Github\n",
        "\n",
        "X = pd.read_csv(\"https://raw.githubusercontent.com/alejandromanas/GoogleColab_public/master/bookings/files/X.csv\", delimiter = ',')\n",
        "Y = pd.read_csv(\"https://raw.githubusercontent.com/alejandromanas/GoogleColab_public/master/bookings/files/Y.csv\", delimiter = ',')\n",
        "Y=Y.to_numpy().ravel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ots15BxbzL3E",
        "colab_type": "text"
      },
      "source": [
        "### Splitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAYXJvdPetPr",
        "colab_type": "text"
      },
      "source": [
        "### XGBOOST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7qUyRrSeyzS",
        "colab_type": "code",
        "outputId": "c27a1117-0ea2-4267-a440-fe1e1a0a2b25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def XGBC_Boss(X,Y):\n",
        "    \n",
        "    # time \n",
        "    _start_time = time.time()\n",
        "    \n",
        "    tic()\n",
        "    \n",
        "    # Model\n",
        "    \n",
        "    xgbmodel=XGBClassifier()\n",
        "    \n",
        "    xgbmodel.get_params()\n",
        "    \n",
        "    params={'base_score': [0.8], # prediccion inicial\n",
        "         'booster': ['gbtree'], # (gbtree, gblinear, dart)\n",
        "         'colsample_bylevel': [1], # ratio de columnas en cada nivel\n",
        "         'colsample_bytree': [0.8], # ratio de columnas por tree\n",
        "         'gamma': [0.01],    # minimo \"loss\" reduccion para crear un nuevo split. Larger-> conservative\n",
        "         'learning_rate': [0.01], # (eta) aportacion de cada arbol al modelo\n",
        "         'max_depth': [6], # maxima profundidad en cada arbol\n",
        "         'min_child_weight': [1], # minimo numero samples por hoja\n",
        "         'missing': [None], # si queremos reemplazar los missings por un numero\n",
        "         'n_estimators': [400], # numero de arboles\n",
        "         'n_jobs': [1], # trabajos en paralelo\n",
        "         'objective': ['binary:logistic'],#  Output. Tipo de funci√≥n que estamos estimando\n",
        "         'random_state': [15], # seed para generar los folds\n",
        "         'reg_alpha': [0.01], # L1 regularitacion\n",
        "         'reg_lambda': [0.01], # L2 regularitacion\n",
        "         'scale_pos_weight': [1],\n",
        "         'subsample': [0.9]} # ratio de muestras por cada arbol \n",
        "    \n",
        "    \n",
        "    # kfold = model_selection.StratifiedKFold(n_splits=3, random_state=15)\n",
        "    kfold = model_selection.StratifiedShuffleSplit(n_splits=3, random_state=15)\n",
        "    grid_solver = GridSearchCV(estimator = xgbmodel, # model to train\n",
        "                       param_grid = params, # param_grid\n",
        "                       scoring = ['accuracy'],\n",
        "                       cv = kfold,\n",
        "                        #n_jobs=3, \n",
        "                        n_jobs=-1,\n",
        "                       refit = 'accuracy',\n",
        "                       verbose = 2)\n",
        "    \n",
        "    model_result_xgboost = grid_solver.fit(X,Y)\n",
        "    \n",
        "    # return predictions\n",
        "    Y_pred = pd.Series(model_result_xgboost.predict(X))\n",
        "    Y_prob= model_result_xgboost.predict_proba(X)\n",
        "    \n",
        "    # Metrics and parameters\n",
        "\n",
        "    ###\n",
        "    print('Results ********** ')\n",
        "   \n",
        "    print('Best score auc: '+ str(model_result_xgboost.best_score_))\n",
        "    \n",
        "    print('Best parameters:',str(model_result_xgboost.best_params_))\n",
        "    print('Results :',str(model_result_xgboost.cv_results_))\n",
        "    \n",
        "    print('********** TRAIN ********** ')\n",
        "    \n",
        "    predict_metrics(X_train,y_train,model_result_xgboost)\n",
        "        \n",
        "    print('********** TEST ********** ')\n",
        "    predict_metrics(X_test,y_test,model_result_xgboost)\n",
        "    \n",
        "    print('********** ALL DATA ********** ')\n",
        "    y_pred,y_prob=predict_metrics(X,y,model_result_xgboost)\n",
        "    predict_metrics(X,Y,model_result_xgboost)\n",
        "\n",
        "    # model_result_xgboost.predict(X)\n",
        "    xgbm=model_result_xgboost.best_estimator_\n",
        "    \n",
        "    # Plot importance PENDING\n",
        "    fig, ax = plt.subplots(figsize=(20, 15))\n",
        "    xgb.plot_importance(xgbm,ax=ax)\n",
        "    \n",
        "    tac() # time elapsed\n",
        "      \n",
        "    return Y_pred,Y_prob,model_result_xgboost\n",
        "\n",
        "Y_pred,Y_prob,model_result_xgboost=XGBC_Boss(X,Y)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:  4.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Results ********** \n",
            "Best score auc: 0.8299690091297429\n",
            "Best parameters: {'base_score': 0.8, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0.01, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 1, 'missing': None, 'n_estimators': 400, 'n_jobs': 1, 'objective': 'binary:logistic', 'random_state': 15, 'reg_alpha': 0.01, 'reg_lambda': 0.01, 'scale_pos_weight': 1, 'subsample': 0.9}\n",
            "Results : {'mean_fit_time': array([128.72356447]), 'std_fit_time': array([26.89969955]), 'mean_score_time': array([0.30383579]), 'std_score_time': array([0.03359895]), 'param_base_score': masked_array(data=[0.8],\n",
            "             mask=[False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_booster': masked_array(data=['gbtree'],\n",
            "             mask=[False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_colsample_bylevel': masked_array(data=[1],\n",
            "             mask=[False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_colsample_bytree': masked_array(data=[0.8],\n",
            "             mask=[False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_gamma': masked_array(data=[0.01],\n",
            "             mask=[False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_learning_rate': masked_array(data=[0.01],\n",
            "             mask=[False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_max_depth': masked_array(data=[6],\n",
            "             mask=[False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_min_child_weight': masked_array(data=[1],\n",
            "             mask=[False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_missing': masked_array(data=[None],\n",
            "             mask=[False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_n_estimators': masked_array(data=[400],\n",
            "             mask=[False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_n_jobs': masked_array(data=[1],\n",
            "             mask=[False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_objective': masked_array(data=['binary:logistic'],\n",
            "             mask=[False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_random_state': masked_array(data=[15],\n",
            "             mask=[False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_reg_alpha': masked_array(data=[0.01],\n",
            "             mask=[False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_reg_lambda': masked_array(data=[0.01],\n",
            "             mask=[False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_scale_pos_weight': masked_array(data=[1],\n",
            "             mask=[False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_subsample': masked_array(data=[0.9],\n",
            "             mask=[False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'params': [{'base_score': 0.8, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0.01, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 1, 'missing': None, 'n_estimators': 400, 'n_jobs': 1, 'objective': 'binary:logistic', 'random_state': 15, 'reg_alpha': 0.01, 'reg_lambda': 0.01, 'scale_pos_weight': 1, 'subsample': 0.9}], 'split0_test_accuracy': array([0.82795879]), 'split1_test_accuracy': array([0.83273306]), 'split2_test_accuracy': array([0.82921518]), 'mean_test_accuracy': array([0.82996901]), 'std_test_accuracy': array([0.00202066]), 'rank_test_accuracy': array([1], dtype=int32)}\n",
            "********** TRAIN ********** \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-e424b76a4258>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_prob\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_result_xgboost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m \u001b[0mY_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_prob\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_result_xgboost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXGBC_Boss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-27-e424b76a4258>\u001b[0m in \u001b[0;36mXGBC_Boss\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'********** TRAIN ********** '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mpredict_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_result_xgboost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'********** TEST ********** '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHttZZ9hZkJ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "67e00e22-509e-4a0c-f9f4-5fdbb4fc765b"
      },
      "source": [
        "Y.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(119390,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akDrisAQtP1a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "2d5d96e5-1714-4bf1-b56f-e37689e575e7"
      },
      "source": [
        "Y_array.ravel().shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(119390,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bBy4IgmcqmR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_metrics(X,y,model):\n",
        "        y_pred = pd.Series(model.predict(X))\n",
        "        y_prob= model.predict_proba(X) \n",
        "        \n",
        "        # Accuracy  \n",
        "        print('Score Acc',str(metrics.accuracy_score(y,y_pred)))\n",
        "        \n",
        "        # AUC\n",
        "        fpr, tpr, threshold = metrics.roc_curve(y, y_prob[:,1])\n",
        "        roc_auc = metrics.auc(fpr, tpr)\n",
        "        print('AUC = %0.2f' % roc_auc)\n",
        "        \n",
        "        # Logloss\n",
        "        Logloss = metrics.log_loss(y, y_prob[:,1])\n",
        "        print('LogLoss = %0.2f' % Logloss)\n",
        "        \n",
        "        return y_pred,y_prob\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeOLRS26tSKw",
        "colab_type": "text"
      },
      "source": [
        "### lightGBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8eJZk-Ormlk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def light_LGBM(X,y,param_grid):\n",
        "    \n",
        "  _start_time = time.time()\n",
        "  tic()\n",
        "     \n",
        "  indexes_of_categories=[]\n",
        "    \n",
        "  lbl = preprocessing.LabelEncoder()\n",
        "    \n",
        "  for i in range(X.shape[1]):\n",
        "      if X.dtypes[i]=='object':\n",
        "          indexes_of_categories.append(i)\n",
        "          lbl.fit(X.iloc[:,i])\n",
        "          X.iloc[:,i]=lbl.transform(X.iloc[:,i])\n",
        "        \n",
        "  # Splitting\n",
        "           \n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)            \n",
        "          \n",
        "  # gkf = KFold(n_splits=5, shuffle=True, random_state=42).split(X=train, y=y)\n",
        "            \n",
        "  gkf = KFold(n_splits=5, shuffle=True, random_state=42).split(X=X_train, y=y_train)\n",
        "    \n",
        "   \n",
        "  # lgb_estimator = lgb.LGBMClassifier(boosting_type='gbdt',  objective='binary', num_boost_round=2000, learning_rate=0.01, metric='auc',categorical_feature=indexes_of_categories)\n",
        "    \n",
        "   \n",
        "  lgb_estimator = lgb.LGBMClassifier(boosting_type='gbdt',  objective='binary',num_boost_round=2000)\n",
        "    \n",
        "  print('Fitting...')\n",
        "    \n",
        "  scoring = ['roc_auc']\n",
        "  refit='roc_auc'\n",
        "  # scoring = ['accuracy']\n",
        "  # refit='accuracy'\n",
        "   \n",
        "  gsearch = GridSearchCV(estimator=lgb_estimator, param_grid=param_grid, cv=gkf,scoring=scoring,refit=refit)\n",
        "    \n",
        "  lgb_model = gsearch.fit(X=X_train, y=y_train)\n",
        "    \n",
        "\n",
        "\n",
        "  print('Results ********** ')\n",
        "    \n",
        "  print('Best score auc: '+ str(lgb_model.best_score_))\n",
        "    \n",
        "  print('Best parameters:',str(lgb_model.best_params_))\n",
        "  print('Results :',str(lgb_model.cv_results_))\n",
        "  # results=pd.DataFrame(lgb_model.cv_results_)\n",
        "    \n",
        "  print('********** TRAIN ********** ')\n",
        "    \n",
        "  predict_metrics(X_train,y_train,lgb_model)\n",
        "        \n",
        "  # # return predictions TRAIN\n",
        "  # y_train_pred=pd.DataFrame()\n",
        "  # y_train_pred = pd.Series(lgb_model.predict(X_train))\n",
        "  # y_train_prob= lgb_model.predict_proba(X_train) \n",
        "    \n",
        "  # print('Score Acc',str(metrics.accuracy_score(y_train,y_train_pred)))\n",
        "    \n",
        "  # fpr, tpr, threshold = metrics.roc_curve(y_train, y_train_prob[:,1])\n",
        "  # roc_auc = metrics.auc(fpr, tpr)\n",
        "  # print('AUC = %0.2f' % roc_auc)\n",
        "    \n",
        "  # Logloss = metrics.log_loss(y_train, y_train_prob[:,1])\n",
        "  # print('LogLoss = %0.2f' % Logloss)\n",
        "    \n",
        "  print('********** TEST ********** ')\n",
        "  predict_metrics(X_test,y_test,lgb_model)\n",
        "  # # return predictions TEST\n",
        "  # y_test_pred=pd.DataFrame()\n",
        "  # y_test_pred = pd.Series(lgb_model.predict(X_test))\n",
        "  # y_test_prob= lgb_model.predict_proba(X_test) \n",
        "    \n",
        "  # print('Score Acc',str(metrics.accuracy_score(y_test,y_test_pred)))\n",
        "    \n",
        "  # fpr, tpr, threshold = metrics.roc_curve(y_test, y_test_prob[:,1])\n",
        "  # roc_auc = metrics.auc(fpr, tpr)\n",
        "  # print('AUC = %0.2f' % roc_auc)\n",
        "    \n",
        "  # Logloss = metrics.log_loss(y_test, y_test_prob[:,1])\n",
        "  # print('LogLoss = %0.2f' % Logloss)\n",
        "    \n",
        "  print('********** ALL DATA ********** ')\n",
        "  y_pred,y_prob=predict_metrics(X,y,lgb_model)\n",
        "  # return predictions TEST\n",
        "  # y_test_pred=pd.DataFrame()\n",
        "  # y_pred = pd.Series(lgb_model.predict(X))\n",
        "  # y_prob= lgb_model.predict_proba(X) \n",
        "    \n",
        "  # print('Score Acc',str(metrics.accuracy_score(y,y_pred)))\n",
        "    \n",
        "  # fpr, tpr, threshold = metrics.roc_curve(y, y_prob[:,1])\n",
        "  # roc_auc = metrics.auc(fpr, tpr)\n",
        "  # print('AUC = %0.2f' % roc_auc)\n",
        "    \n",
        "  # Logloss = metrics.log_loss(y, y_prob[:,1])\n",
        "  # print('LogLoss = %0.2f' % Logloss)\n",
        "   \n",
        "  # Plot importance PENDING\n",
        "  # fig, ax = plt.subplots(figsize=(20, 15))\n",
        "    \n",
        "  # lgb.plot_importance(lgb_estimator,ax=ax)\n",
        "  # lgb.plot_importance(gsearch.Booster,ax=ax)\n",
        "  # lgb.plot_importance(lgb_model.Booster_Booster,ax=ax)\n",
        "  # lgb.plot_importance(lgb_model,ax=ax)\n",
        "    \n",
        "  # plot_tree(lgb_model._Booster)\n",
        "    \n",
        "    \n",
        "  # lgb_model.plot_importance()\n",
        "  # # fig = plot_imp.figure\n",
        "  # # fig.set_size_inches(5, 10)\n",
        "  # plt.savefig('lightLGBM.png')\n",
        "        \n",
        "   \n",
        "  # time\n",
        "  tac()\n",
        "    \n",
        "  return y_pred,y_prob,\n",
        "\n",
        "param_grid = {\n",
        "'num_leaves': [31],\n",
        "  # 'num_boost_round': [2000],\n",
        "  'learning_rate':[0.1],\n",
        "  # 'reg_alpha': [0.1],\n",
        "  'min_data_in_leaf': [30],\n",
        "  'lambda_l1': [0],\n",
        "  'lambda_l2': [0],\n",
        "  'min_data_in_leaf':[100],\n",
        "  'max_depth': [3],\n",
        "  # 'num_boost_round': [2000]\n",
        "  # n_estimators=100,\n",
        "  # subsample=1.0, \n",
        "  }    \n",
        "\n",
        "y_pred,y_prob = light_LGBM(X,y,param_grid)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}